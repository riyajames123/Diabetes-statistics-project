{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec2f3b6-02bb-40dc-9b8d-2e36c738d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c2d58-2dfc-4353-945c-8ba42dd2b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_lipids = pd.read_csv('normalized_lipids.csv')\n",
    "normalized_rnaseq = pd.read_csv('normalized_rnaseq.csv')\n",
    "metadata = pd.read_csv('t2d_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4b228-409f-4607-97e8-2ffe701e986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64930eac-8970-4f27-a727-71a21dcc50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_rnaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1b031-9669-4ebb-a0d0-3e3e7e993d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_lipids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724ec99-0f2a-4532-b197-27d3b427300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(dataframe):\n",
    "    col = pd.DataFrame({'col':dataframe.isnull().sum().keys()})\n",
    "    missing_val = pd.DataFrame({'miss_val':dataframe.isnull().sum().values})\n",
    "    miss = pd.concat([col,missing_val],axis = 1)\n",
    "    null_df = miss[miss['miss_val'] != 0]\n",
    "    if null_df.shape[0] == 0:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"This Dataframe does not contains any null values\")\n",
    "        print(\"------------------------------------------------\")\n",
    "    else:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"This Dataframe have some missing values...\")\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"Checking for the columns which contains missing values\")\n",
    "        print(\"------------------------------------------------\")\n",
    "        print('Out of total' , dataframe.shape[0],'samples we have the following missing values :')\n",
    "        col_mis = list(null_df['col'])\n",
    "        for val in col_mis:\n",
    "            val_count = int(null_df[null_df['col'] == val]['miss_val'].iloc[0])\n",
    "            percent = val_count / dataframe.shape[0] * 100\n",
    "            print(f\"{percent:.2f}% values are missing in: {val}\")\n",
    "            \n",
    "        print(\"------------------------------------------------\") \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    return miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157397b-cbb5-4070-a90d-61a1e7ab7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca3f7f-0636-4dd3-9781-1932c338ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_biological_data(df):\n",
    "    \"\"\"\n",
    "    Comprehensive imputation strategy for biological data with detailed methods for each column\n",
    "    \"\"\"\n",
    "    imputed_df = df.copy()\n",
    "    \n",
    "    # 1. Age (1.48% missing)\n",
    "    imputed_df['Age'] = imputed_df['Age'].fillna(imputed_df['Age'].median())\n",
    "    \n",
    "    # 2. BMI (1.48% missing)\n",
    "    imputed_df['BMI'] = imputed_df['BMI'].fillna(imputed_df['BMI'].median())\n",
    "    \n",
    "    # 3. HbA1c (2.96% missing)\n",
    "    knn_imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "    imputed_df['HbA1c'] = knn_imputer.fit_transform(imputed_df[['HbA1c', 'BMI', 'Age']])[:,0]\n",
    "    \n",
    "    # 4. OGTT (43.70% missing)\n",
    "    # Modified MICE imputer without sample_posterior\n",
    "    mice_imputer = IterativeImputer(\n",
    "        random_state=42,\n",
    "        max_iter=10,\n",
    "        min_value=0,\n",
    "        estimator=RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            n_jobs=-1  # Use all available cores\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Include relevant predictors for OGTT\n",
    "    predictors = ['OGTT', 'HbA1c', 'BMI', 'Age']\n",
    "    temp_data = imputed_df[predictors].copy()\n",
    "    imputed_values = mice_imputer.fit_transform(temp_data)\n",
    "    imputed_df['OGTT'] = imputed_values[:,0]\n",
    "    \n",
    "    # Validate biological ranges\n",
    "    imputed_df = validate_biological_ranges(imputed_df)\n",
    "    \n",
    "    return imputed_df\n",
    "\n",
    "def validate_biological_ranges(df):\n",
    "    \"\"\"\n",
    "    Ensure imputed values are within biological ranges\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Age constraints\n",
    "    df.loc[df['Age'] < 0, 'Age'] = df['Age'].median()\n",
    "    df.loc[df['Age'] > 120, 'Age'] = df['Age'].median()\n",
    "    \n",
    "    # BMI constraints\n",
    "    df.loc[df['BMI'] < 10, 'BMI'] = df['BMI'].median()\n",
    "    df.loc[df['BMI'] > 100, 'BMI'] = df['BMI'].median()\n",
    "    \n",
    "    # HbA1c constraints (typical range 3-15%)\n",
    "    df.loc[df['HbA1c'] < 3, 'HbA1c'] = 3\n",
    "    df.loc[df['HbA1c'] > 15, 'HbA1c'] = 15\n",
    "    \n",
    "    # OGTT constraints (typical range 0-500 mg/dL)\n",
    "    df.loc[df['OGTT'] < 0, 'OGTT'] = 0\n",
    "    df.loc[df['OGTT'] > 500, 'OGTT'] = 500\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_imputation_results(original_df, imputed_df):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of imputation results\n",
    "    \"\"\"\n",
    "    columns = ['Age', 'BMI', 'HbA1c', 'OGTT']\n",
    "    \n",
    "    for col in columns:\n",
    "        print(f\"\\nAnalysis for {col}:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Missing value analysis\n",
    "        missing_count = original_df[col].isnull().sum()\n",
    "        missing_percent = (missing_count / len(original_df)) * 100\n",
    "        print(f\"Original missing values: {missing_count} ({missing_percent:.2f}%)\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        orig_stats = original_df[col].describe()\n",
    "        imp_stats = imputed_df[col].describe()\n",
    "        \n",
    "        stats_comparison = pd.DataFrame({\n",
    "            'Original': orig_stats,\n",
    "            'Imputed': imp_stats\n",
    "        })\n",
    "        print(\"\\nDescriptive Statistics Comparison:\")\n",
    "        print(stats_comparison)\n",
    "        \n",
    "        # Distribution plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot original data distribution\n",
    "        sns.kdeplot(data=original_df[col].dropna(), \n",
    "                   label='Original', alpha=0.5)\n",
    "        \n",
    "        # Plot imputed data distribution\n",
    "        sns.kdeplot(data=imputed_df[col], \n",
    "                   label='Imputed', alpha=0.5)\n",
    "        \n",
    "        plt.title(f'Distribution Comparison for {col}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        imputed_df = impute_biological_data(metadata)\n",
    "        \n",
    "        \n",
    "        # Analyze results\n",
    "        analyze_imputation_results(metadata, imputed_df)\n",
    "        \n",
    "        print(\"\\nImputation completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bea17f-495e-4a2d-b49f-c72dd37b8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import probplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00532d04-cc43-4f73-acee-2fc5a3fc8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def impute_ogtt_preserving_distribution(df, column='OGTT'):\n",
    "    \"\"\"\n",
    "    Impute OGTT values while preserving the original distribution\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 1. Separate missing and non-missing data\n",
    "    missing_mask = df_copy[column].isnull()\n",
    "    known_values = df_copy[~missing_mask][column]\n",
    "    \n",
    "    # 2. Prepare predictors for imputation\n",
    "    predictors = ['HbA1c', 'BMI', 'Age']\n",
    "    \n",
    "    # 3. Standardize predictors\n",
    "    scaler = StandardScaler()\n",
    "    X_known = scaler.fit_transform(df_copy[~missing_mask][predictors])\n",
    "    X_missing = scaler.transform(df_copy[missing_mask][predictors])\n",
    "    \n",
    "    # 4. Train Random Forest model on non-missing data\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=3\n",
    "    )\n",
    "    rf_model.fit(X_known, known_values)\n",
    "    \n",
    "    # 5. Generate multiple predictions for each missing value\n",
    "    n_iterations = 10\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        predictions = rf_model.predict(X_missing)\n",
    "        all_predictions.append(predictions)\n",
    "    \n",
    "    # 6. Add random noise based on original distribution\n",
    "    std_dev = known_values.std() * 0.1  # 10% of original std\n",
    "    final_predictions = np.mean(all_predictions, axis=0)\n",
    "    noise = np.random.normal(0, std_dev, size=len(final_predictions))\n",
    "    final_predictions += noise\n",
    "    \n",
    "    # 7. Ensure predictions follow original distribution\n",
    "    def match_distribution(original_values, predicted_values):\n",
    "        \"\"\"\n",
    "        Adjust predicted values to better match the original distribution\n",
    "        \"\"\"\n",
    "        # Get original percentiles\n",
    "        orig_percentiles = np.percentile(original_values, np.linspace(0, 100, 20))\n",
    "        pred_percentiles = np.percentile(predicted_values, np.linspace(0, 100, 20))\n",
    "        \n",
    "        # Create interpolation function\n",
    "        from scipy.interpolate import interp1d\n",
    "        transform_func = interp1d(pred_percentiles, orig_percentiles, \n",
    "                                bounds_error=False, fill_value='extrapolate')\n",
    "        \n",
    "        # Transform predicted values\n",
    "        adjusted_predictions = transform_func(predicted_values)\n",
    "        \n",
    "        # Ensure values are within biological limits\n",
    "        adjusted_predictions = np.clip(adjusted_predictions, 0, 500)\n",
    "        \n",
    "        return adjusted_predictions\n",
    "    \n",
    "    # Apply distribution matching\n",
    "    final_predictions = match_distribution(known_values, final_predictions)\n",
    "    \n",
    "    # 8. Insert predictions back into dataframe\n",
    "    df_copy.loc[missing_mask, column] = final_predictions\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def impute_biological_data(df):\n",
    "    \"\"\"\n",
    "    Comprehensive imputation strategy for biological data\n",
    "    \"\"\"\n",
    "    imputed_df = df.copy()\n",
    "    \n",
    "    # 1. Age (1.48% missing)\n",
    "    imputed_df['Age'] = imputed_df['Age'].fillna(imputed_df['Age'].median())\n",
    "    \n",
    "    # 2. BMI (1.48% missing)\n",
    "    imputed_df['BMI'] = imputed_df['BMI'].fillna(imputed_df['BMI'].median())\n",
    "    \n",
    "    # 3. HbA1c (2.96% missing)\n",
    "    knn_imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "    imputed_df['HbA1c'] = knn_imputer.fit_transform(imputed_df[['HbA1c', 'BMI', 'Age']])[:,0]\n",
    "    \n",
    "    # 4. OGTT (43.70% missing) - Using the new distribution-preserving method\n",
    "    imputed_df = impute_ogtt_preserving_distribution(imputed_df)\n",
    "    \n",
    "    return imputed_df\n",
    "\n",
    "def analyze_distributions(original_df, imputed_df, column):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the distributions before and after imputation\n",
    "    \"\"\"\n",
    "  \n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Density plots\n",
    "    plt.subplot(131)\n",
    "    sns.kdeplot(data=original_df[column].dropna(), label='Original', alpha=0.5)\n",
    "    sns.kdeplot(data=imputed_df[column], label='Imputed', alpha=0.5)\n",
    "    plt.title(f'{column} Distribution Comparison')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 2: Q-Q plot\n",
    "    plt.subplot(132)\n",
    "    probplot(imputed_df[column], dist=\"norm\", plot=plt)\n",
    "    plt.title('Q-Q Plot of Imputed Data')\n",
    "    \n",
    "    # Plot 3: Box plots\n",
    "    plt.subplot(133)\n",
    "    plt.boxplot([original_df[column].dropna(), imputed_df[column]], \n",
    "                labels=['Original', 'Imputed'])\n",
    "    plt.title('Box Plot Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical tests\n",
    "    print(f\"\\nStatistical Analysis for {column}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Kolmogorov-Smirnov test\n",
    "    ks_stat, p_value = stats.ks_2samp(\n",
    "        original_df[column].dropna(),\n",
    "        imputed_df[column]\n",
    "    )\n",
    "    print(f\"KS test p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Basic statistics comparison\n",
    "    stats_comparison = pd.DataFrame({\n",
    "        'Original': original_df[column].describe(),\n",
    "        'Imputed': imputed_df[column].describe()\n",
    "    })\n",
    "    print(\"\\nDescriptive Statistics:\")\n",
    "    print(stats_comparison)\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Impute the data\n",
    "    imputed_df = impute_biological_data(metadata)\n",
    "    \n",
    "    # Analyze OGTT distribution\n",
    "    analyze_distributions(metadata, imputed_df, 'OGTT')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d255aa5-f19d-4786-9fcd-6e1c131721f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_metadata = imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155224d-a554-4650-bd9c-64043ea01ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_outliers(df):\n",
    "    \"\"\"\n",
    "    Plots distributions and boxplots to visualize outliers in numeric columns of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Distribution plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df[col], kde=True, bins=30, color='skyblue', alpha=0.6)\n",
    "        plt.title(f'Distribution: {col}')\n",
    "\n",
    "        # Boxplot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(x=df[col], color='salmon')\n",
    "        plt.title(f'Boxplot: {col}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f17bea-3e76-4f49-b354-2938b6b21714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_outliers(normalized_lipids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7cda1-0bf2-4a94-8cdc-808ac7d42cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_outliers(normalized_rnaseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216a515-6941-4cc5-8c7e-f3aed5ecbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def remove_outliers_iqr(df, fill_method=None):\n",
    "    \"\"\"\n",
    "    Removes outlier expression values per gene using IQR method.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Normalized RNA-seq data (genes as rows, samples as columns).\n",
    "        fill_method (str or None): 'median', 'mean', or None (keep NaN).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outlier values removed or imputed.\n",
    "    \"\"\"\n",
    "    cleaned_df = df.copy()\n",
    "    col_1 = cleaned_df.iloc[0:,0]\n",
    "    cleaned_df = cleaned_df.iloc[0:,1:]\n",
    "\n",
    "    for gene in cleaned_df.index:\n",
    "        row = cleaned_df.loc[gene]\n",
    "        Q1 = row.quantile(0.25)\n",
    "        Q3 = row.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Find outliers\n",
    "        mask = (row < lower) | (row > upper)\n",
    "\n",
    "        # Replace outliers\n",
    "        if fill_method == 'median':\n",
    "            cleaned_df.loc[gene, mask] = row.median()\n",
    "        elif fill_method == 'mean':\n",
    "            cleaned_df.loc[gene, mask] = row.mean()\n",
    "        else:\n",
    "            cleaned_df.loc[gene, mask] = np.nan\n",
    "    cleaned_df = pd.concat([col_1,cleaned_df],axis = 1)\n",
    "\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e712075-9bfc-4d93-9326-e609ac615e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_lipid_outlier_removed = remove_outliers_iqr(normalized_lipids,fill_method='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f50d4-f7a1-4de5-b5f1-c83a8f0d5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "def detect_and_remove_outlier_samples(df, method=\"PCA\", n_clusters=3, threshold_percentile=95):\n",
    "    \"\"\"\n",
    "    Detect and remove outlier samples using PCA or KMeans clustering.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Normalized RNA-seq data (genes as rows, samples as columns).\n",
    "        method (str): \"PCA\" or \"Clustering\" method for outlier detection.\n",
    "        n_clusters (int): Number of clusters for KMeans (if method is \"Clustering\").\n",
    "        threshold_percentile (int): Percentile threshold to classify outliers.\n",
    "        \n",
    "    Returns:\n",
    "        cleaned_df (pd.DataFrame): DataFrame with outlier samples removed.\n",
    "        outlier_samples (list): List of column names of outlier samples.\n",
    "        explained_variance (numpy.array): Explained variance ratios from PCA\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make a copy of the original dataframe\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Store the first column (usually gene names/IDs)\n",
    "        first_col_name = df_copy.columns[0]\n",
    "        first_col = df_copy[[first_col_name]]\n",
    "        \n",
    "        # Get the data columns (excluding the first column)\n",
    "        data_cols = df_copy.columns[1:]\n",
    "        data_df = df_copy[data_cols]\n",
    "        \n",
    "        # Transpose data for scaling (samples as rows)\n",
    "        df_transposed = data_df.T\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(df_transposed)\n",
    "        \n",
    "        outlier_samples = []\n",
    "        explained_variance = None\n",
    "        \n",
    "        if method == \"PCA\":\n",
    "            # Apply PCA\n",
    "            pca = PCA(n_components=2)\n",
    "            pca_result = pca.fit_transform(scaled_data)\n",
    "            explained_variance = pca.explained_variance_ratio_\n",
    "            \n",
    "            # Calculate distances from origin\n",
    "            distances = np.sqrt(np.sum(pca_result**2, axis=1))\n",
    "            \n",
    "            # Define threshold\n",
    "            threshold = np.percentile(distances, threshold_percentile)\n",
    "            \n",
    "            # Identify outliers\n",
    "            outlier_mask = distances > threshold\n",
    "            outlier_samples = data_df.columns[outlier_mask].tolist()\n",
    "            \n",
    "            # Plotting\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(pca_result[~outlier_mask, 0], pca_result[~outlier_mask, 1], \n",
    "                       c='blue', label='Normal Samples')\n",
    "            plt.scatter(pca_result[outlier_mask, 0], pca_result[outlier_mask, 1], \n",
    "                       c='red', label='Outliers')\n",
    "            plt.title('PCA of RNA-seq Samples')\n",
    "            plt.xlabel(f'PC1 ({explained_variance[0]:.2%} variance explained)')\n",
    "            plt.ylabel(f'PC2 ({explained_variance[1]:.2%} variance explained)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        elif method == \"Clustering\":\n",
    "            # Apply KMeans\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "            \n",
    "            # Calculate distances to nearest cluster center\n",
    "            distances = np.min(kmeans.transform(scaled_data), axis=1)\n",
    "            \n",
    "            # Define threshold\n",
    "            threshold = np.percentile(distances, threshold_percentile)\n",
    "            \n",
    "            # Identify outliers\n",
    "            outlier_mask = distances > threshold\n",
    "            outlier_samples = data_df.columns[outlier_mask].tolist()\n",
    "            \n",
    "            # Apply PCA for visualization\n",
    "            pca = PCA(n_components=2)\n",
    "            pca_result = pca.fit_transform(scaled_data)\n",
    "            explained_variance = pca.explained_variance_ratio_\n",
    "            \n",
    "            # Plotting\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], \n",
    "                                c=cluster_labels, cmap='Set2')\n",
    "            plt.scatter(pca_result[outlier_mask, 0], pca_result[outlier_mask, 1], \n",
    "                       c='red', marker='x', s=100, label='Outliers')\n",
    "            plt.title('Clustering of RNA-seq Samples')\n",
    "            plt.xlabel(f'PC1 ({explained_variance[0]:.2%} variance explained)')\n",
    "            plt.ylabel(f'PC2 ({explained_variance[1]:.2%} variance explained)')\n",
    "            plt.legend()\n",
    "            plt.colorbar(scatter, label='Cluster')\n",
    "            plt.show()\n",
    "        \n",
    "        # Print outlier information\n",
    "        print(f\"\\nNumber of outliers detected: {len(outlier_samples)}\")\n",
    "        print(\"Outlier samples:\", outlier_samples)\n",
    "        \n",
    "        # Remove outliers\n",
    "        columns_to_keep = [col for col in data_df.columns if col not in outlier_samples]\n",
    "        cleaned_data = data_df[columns_to_keep]\n",
    "        \n",
    "        # Combine first column with cleaned data\n",
    "        cleaned_df = pd.concat([first_col, cleaned_data], axis=1)\n",
    "        \n",
    "        # Print shape information\n",
    "        print(f\"\\nOriginal shape: {df.shape}\")\n",
    "        print(f\"Cleaned shape: {cleaned_df.shape}\")\n",
    "        \n",
    "        return cleaned_df, outlier_samples, explained_variance\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Example usage with debugging information\n",
    "def test_outlier_removal(df, method=\"PCA\", threshold_percentile=95):\n",
    "    \"\"\"\n",
    "    Test the outlier removal function with detailed debugging information\n",
    "    \"\"\"\n",
    "    print(\"Starting outlier detection...\")\n",
    "    print(f\"Input DataFrame shape: {df.shape}\")\n",
    "    print(f\"Input DataFrame columns: {df.columns.tolist()[:5]}... (first 5)\")\n",
    "    \n",
    "    cleaned_df, outliers, exp_var = detect_and_remove_outlier_samples(\n",
    "        df,\n",
    "        method=method,\n",
    "        threshold_percentile=threshold_percentile\n",
    "    )\n",
    "    \n",
    "    if cleaned_df is not None:\n",
    "        print(\"\\nOutlier removal completed successfully\")\n",
    "        print(f\"Number of columns removed: {len(outliers)}\")\n",
    "        print(f\"Output DataFrame shape: {cleaned_df.shape}\")\n",
    "        print(f\"Output DataFrame columns: {cleaned_df.columns.tolist()[:5]}... (first 5)\")\n",
    "        \n",
    "        # Verify removal\n",
    "        if len(outliers) > 0:\n",
    "            for outlier in outliers:\n",
    "                if outlier in cleaned_df.columns:\n",
    "                    print(f\"WARNING: Outlier {outlier} still present in cleaned data!\")\n",
    "                else:\n",
    "                    print(f\"Confirmed: Outlier {outlier} successfully removed\")\n",
    "    \n",
    "    return cleaned_df, outliers, exp_var\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee170be9-17ab-41ed-a9dc-b4d70e34731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_rnaseq_outlier_removed, outliers,explained_variance = test_outlier_removal(\n",
    "    normalized_rnaseq,\n",
    "    method=\"PCA\",\n",
    "    threshold_percentile=95\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b5efb-ea77-4aba-b4d5-98cc84f5d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_rnaseq_outlier_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e492a90-1bd1-4a1f-8104-9e1306094bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_outliers(normalized_lipid_outlier_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b3a62-bca7-46aa-bf33-24e13be3fb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_outliers(normalized_rnaseq_outlier_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7b60b-10be-49cd-921d-26b3e1a0e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_merging(rnaseq,lipid,metadat):\n",
    "    col_lipid = list(lipid.T.reset_index().iloc[0,0:])\n",
    "    lipid = lipid.T.iloc[1:,]\n",
    "    lipid.columns = col_lipid[1:]#.reset_index()#.rename(columns = {'index':'genes'})\n",
    "    lipid = lipid.reset_index().rename(columns = {'index':'#NAME'})\n",
    "    lipid_merge = lipid.merge(metadat,on = '#NAME',how = 'inner')\n",
    "    \n",
    "    rnaseq = rnaseq.T\n",
    "    col_rnaseq = list(rnaseq.iloc[0,0:])\n",
    "   \n",
    "    rnaseq.columns = col_rnaseq#.reset_index()#.rename(columns = {'index':'genes'})\n",
    "    rnaseq = rnaseq.iloc[1:].reset_index().rename(columns = {'index':'#NAME'})\n",
    "    rnaseq_merge = rnaseq.merge(metadat,on = '#NAME',how = 'inner')\n",
    "   \n",
    "    return rnaseq_merge,lipid_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6e487-7616-4037-a15c-4e056b8d1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq_merge,lipid_merge = data_merging(normalized_rnaseq,normalized_lipids,imputed_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27e06b-ca58-45f4-a786-6468a1bc28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipid_merge.to_csv(\"lipid_merge.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35bcda8-3abd-4369-941d-d1e77ea7771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def assess_samplewise_distribution_and_normality(df, num_samples=5):\n",
    "    \"\"\"\n",
    "    Assess distribution, skewness, and normality of RNA-seq expression across samples (columns).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Normalized RNA-seq dataframe (samples as columns).\n",
    "        num_samples (int): Number of random samples (columns) to visualize.\n",
    "\n",
    "    Returns:\n",
    "        normality_df (pd.DataFrame): Summary table with skewness and normality p-values.\n",
    "    \"\"\"\n",
    "    # Ensure index is not 'Unnamed' column\n",
    "    if df.columns[0] == \"Unnamed: 0\":\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    results = []\n",
    "    sampled_cols = np.random.choice(df.columns, size=min(num_samples, df.shape[1]), replace=False)\n",
    "\n",
    "    for sample in sampled_cols:\n",
    "        data = df[sample].dropna()\n",
    "        gene_skew = skew(data)\n",
    "        stat, p_value = shapiro(data)\n",
    "\n",
    "        results.append({\n",
    "            'Sample': sample,\n",
    "            'Skewness': gene_skew,\n",
    "            'Shapiro_pval': p_value,\n",
    "            'Is_Normal (p>0.05)': p_value > 0.05\n",
    "        })\n",
    "\n",
    "        # Plot distribution\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Histogram + KDE\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(data, kde=True, bins=30, color='skyblue', edgecolor='black')\n",
    "        plt.axvline(data.mean(), color='red', linestyle='--', label='Mean')\n",
    "        plt.title(f'Distribution for Sample: {sample}')\n",
    "        plt.legend()\n",
    "\n",
    "        # QQ Plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        probplot(data, dist=\"norm\", plot=plt)\n",
    "        plt.title(f'QQ Plot for Sample: {sample}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    normality_df = pd.DataFrame(results)\n",
    "    return normality_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff9414-0a22-41e7-9f11-7cd26a43af38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normality_df_rnaseq = assess_samplewise_distribution_and_normality(normalized_rnaseq_outlier_removed, num_samples=len(normalized_rnaseq_outlier_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde0aa5-f13d-4778-86cb-ef343a9f718e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normality_df_lipid = assess_samplewise_distribution_and_normality(normalized_lipid_outlier_removed, num_samples=len(normalized_lipid_outlier_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d603c9-8206-4bbc-bb6e-6c6a379652ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_df_lipid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76867b-62f9-4568-99c1-e1a9fe256a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_df_rnaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fae99-ebe3-43c2-9d4e-53d149116b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_transformations_and_check_normality(df, num_samples=5):\n",
    "    \"\"\"\n",
    "    Apply various transformations sample-wise and assess normality.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Normalized RNA-seq data (samples as columns).\n",
    "        num_samples (int): Number of random samples to visualize.\n",
    "\n",
    "    Returns:\n",
    "        results_df (pd.DataFrame): Summary of skewness and p-values post-transformation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Drop identifier column if present\n",
    "    if df.columns[0] == \"Unnamed: 0\":\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    transformations = {\n",
    "        'Log1p': lambda x: np.log1p(x),\n",
    "        'Sqrt': lambda x: np.sqrt(np.abs(x)),\n",
    "        'Reciprocal': lambda x: 1 / (x + 1e-6),  # Add small constant to avoid /0\n",
    "        'Z-Score': lambda x: zscore(x, nan_policy='omit')\n",
    "    }\n",
    "\n",
    "    sample_cols = np.random.choice(df.columns, size=min(num_samples, len(df.columns)), replace=False)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for sample in sample_cols:\n",
    "        data = df[sample].dropna()\n",
    "\n",
    "        for name, func in transformations.items():\n",
    "            try:\n",
    "                transformed = func(data)\n",
    "\n",
    "                # Stats\n",
    "                sk = skew(transformed)\n",
    "                pval = shapiro(transformed)[1]\n",
    "\n",
    "                all_results.append({\n",
    "                    \"Sample\": sample,\n",
    "                    \"Transformation\": name,\n",
    "                    \"Skewness\": sk,\n",
    "                    \"Shapiro_pval\": pval,\n",
    "                    \"Is_Normal (p>0.05)\": pval > 0.05\n",
    "                })\n",
    "\n",
    "                # Plotting\n",
    "                plt.figure(figsize=(12, 4))\n",
    "\n",
    "                # Histogram + KDE\n",
    "                plt.subplot(1, 2, 1)\n",
    "                sns.histplot(transformed, kde=True, bins=30, color='skyblue', edgecolor='black')\n",
    "                plt.axvline(transformed.mean(), color='red', linestyle='--', label='Mean')\n",
    "                plt.title(f'{name} - Distribution of {sample}')\n",
    "                plt.legend()\n",
    "\n",
    "                # QQ Plot\n",
    "                plt.subplot(1, 2, 2)\n",
    "                probplot(transformed, dist=\"norm\", plot=plt)\n",
    "                plt.title(f'{name} - QQ Plot of {sample}')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Transformation {name} failed on {sample}: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d30d2-fc50-4039-86bf-50acb63d595c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformation_rnaseq = apply_transformations_and_check_normality(normalized_rnaseq_outlier_removed,len(normalized_rnaseq_outlier_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f49c9-4ac0-4cd8-98f6-b35a3b9b8d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformation_lipid = apply_transformations_and_check_normality(normalized_lipid_outlier_removed,len(normalized_lipid_outlier_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198fdb7-97c6-4864-adc0-0a93e687f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Summarize results for a transformation dataset\n",
    "def summarize_transformations(transformation_df, dataset_name=\"Dataset\"):\n",
    "    summary = (\n",
    "        transformation_df\n",
    "        .groupby(\"Transformation\")\n",
    "        .agg(\n",
    "            Avg_Skewness=('Skewness', 'mean'),\n",
    "            Std_Skewness=('Skewness', 'std'),\n",
    "            Normal_Count=('Is_Normal (p>0.05)', 'sum'),\n",
    "            Total_Samples=('Is_Normal (p>0.05)', 'count')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    summary[\"% Normal (p > 0.05)\"] = (summary[\"Normal_Count\"] / summary[\"Total_Samples\"]) * 100\n",
    "    summary = summary.sort_values([\"% Normal (p > 0.05)\", \"Avg_Skewness\"], ascending=[False, True])\n",
    "\n",
    "    print(f\"\\n===== Summary for {dataset_name} =====\")\n",
    "    print(summary)\n",
    "    return summary\n",
    "\n",
    "# Apply it to both datasets (assuming they're defined)\n",
    "summary_rnaseq = summarize_transformations(transformation_rnaseq, \"RNA-seq\")\n",
    "summary_lipid = summarize_transformations(transformation_lipid, \"Lipidomics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708e95d-cc5d-4cb3-b49e-b687a79ff74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4c91b-8b6f-48cd-8324-f31cf5d6c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c06a2-0178-4dde-8dad-ba694a558768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, kruskal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6ed16-9b7c-4b18-ad2c-1db7c98f3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal, mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb279e-9742-44c3-a113-27ce559714bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_expression_by_diabetes_group(df, group_col='Diagnosis'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Separate metadata and features\n",
    "    metadata = df[[group_col]]\n",
    "    expression = df.drop(columns=['#NAME', group_col, 'Age', 'OGTT', 'HbA1c', 'BMI'])\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in expression.columns:\n",
    "        temp_df = pd.concat([metadata, expression[[feature]]], axis=1)\n",
    "        groups = [group[feature].dropna().values for name, group in temp_df.groupby(group_col)]\n",
    "\n",
    "        # Kruskal-Wallis Test\n",
    "        stat, p = kruskal(*groups)\n",
    "        results.append({'Feature': feature, 'Kruskal_Wallis_stat': stat, 'Kruskal_Wallis_pval': p})\n",
    "\n",
    "    kruskal_df = pd.DataFrame(results)\n",
    "    kruskal_df['adj_pval'] = multipletests(kruskal_df['Kruskal_Wallis_pval'], method='fdr_bh')[1]\n",
    "\n",
    "    # Visualize top 3 significant features\n",
    "    top_features = kruskal_df.sort_values('adj_pval').head(3)['Feature']\n",
    "\n",
    "    for feat in top_features:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.boxplot(data=df, x=group_col, y=feat, palette='Set3')\n",
    "        plt.title(f'Expression Distribution of {feat} by {group_col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Pairwise Mann-Whitney U test\n",
    "    pairwise_results = []\n",
    "    for feature in top_features:\n",
    "        temp_df = pd.concat([metadata, expression[[feature]]], axis=1)\n",
    "        for (g1, g2) in itertools.combinations(temp_df[group_col].unique(), 2):\n",
    "            group1_vals = temp_df[temp_df[group_col] == g1][feature].dropna()\n",
    "            group2_vals = temp_df[temp_df[group_col] == g2][feature].dropna()\n",
    "            stat, pval = mannwhitneyu(group1_vals, group2_vals, alternative='two-sided')\n",
    "            pairwise_results.append({\n",
    "                'Feature': feature,\n",
    "                'Group1': g1,\n",
    "                'Group2': g2,\n",
    "                'U_stat': stat,\n",
    "                'p_value': pval\n",
    "            })\n",
    "\n",
    "    pairwise_df = pd.DataFrame(pairwise_results)\n",
    "    pairwise_df['adj_pval'] = multipletests(pairwise_df['p_value'], method='fdr_bh')[1]\n",
    "\n",
    "    return kruskal_df.sort_values('adj_pval'), pairwise_df.sort_values('adj_pval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376c9b3-bcd4-4337-8efe-647506328d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_results_rnaseq, pairwise_results_rnaseq = analyze_expression_by_diabetes_group(rnaseq_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ea0d4-bd92-4561-bef4-408e4f778c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kruskal_results_rnaseq.head())\n",
    "print(pairwise_results_rnaseq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4527d9-08c5-4f0c-9fdd-938fdc5a83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal, mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_lipid_by_diabetes_group(df, group_col='Diagnosis'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Separate metadata and lipid features\n",
    "    metadata = df[[group_col]]\n",
    "    lipid = df.drop(columns=['#NAME', group_col, 'Age', 'OGTT', 'HbA1c', 'BMI'])\n",
    "\n",
    "    # Ensure all lipid columns are numeric\n",
    "    lipid = lipid.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for feature in lipid.columns:\n",
    "        temp_df = pd.concat([metadata, lipid[[feature]]], axis=1)\n",
    "        groups = [group[feature].dropna().values for name, group in temp_df.groupby(group_col)]\n",
    "\n",
    "        # Kruskal-Wallis Test\n",
    "        stat, p = kruskal(*groups)\n",
    "        results.append({'Feature': feature, 'Kruskal_Wallis_stat': stat, 'Kruskal_Wallis_pval': p})\n",
    "\n",
    "    kruskal_df = pd.DataFrame(results)\n",
    "    kruskal_df['adj_pval'] = multipletests(kruskal_df['Kruskal_Wallis_pval'], method='fdr_bh')[1]\n",
    "\n",
    "    # Visualize top 3 significant features\n",
    "    top_features = kruskal_df.sort_values('adj_pval').head(3)['Feature']\n",
    "\n",
    "    for feat in top_features:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.boxplot(data=df, x=group_col, y=feat, palette='Set2')\n",
    "        plt.title(f'Lipid Distribution of {feat} by {group_col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Pairwise Wilcoxon (Mann-Whitney U) Test for top features\n",
    "    pairwise_results = []\n",
    "    for feature in top_features:\n",
    "        temp_df = pd.concat([metadata, lipid[[feature]]], axis=1)\n",
    "        for (g1, g2) in itertools.combinations(temp_df[group_col].unique(), 2):\n",
    "            group1_vals = temp_df[temp_df[group_col] == g1][feature].dropna()\n",
    "            group2_vals = temp_df[temp_df[group_col] == g2][feature].dropna()\n",
    "\n",
    "            if len(group1_vals) > 0 and len(group2_vals) > 0:\n",
    "                stat, pval = mannwhitneyu(group1_vals, group2_vals, alternative='two-sided')\n",
    "                pairwise_results.append({\n",
    "                    'Feature': feature,\n",
    "                    'Group1': g1,\n",
    "                    'Group2': g2,\n",
    "                    'U_stat': stat,\n",
    "                    'p_value': pval\n",
    "                })\n",
    "\n",
    "    pairwise_df = pd.DataFrame(pairwise_results)\n",
    "    if not pairwise_df.empty:\n",
    "        pairwise_df['adj_pval'] = multipletests(pairwise_df['p_value'], method='fdr_bh')[1]\n",
    "    else:\n",
    "        pairwise_df['adj_pval'] = []\n",
    "\n",
    "    return kruskal_df.sort_values('adj_pval'), pairwise_df.sort_values('adj_pval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0049f9-a81b-45af-b53a-3f44ce552293",
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_results_lipid, pairwise_results_lipid = analyze_lipid_by_diabetes_group(lipid_merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1b5dd-75b1-4e01-905c-e8dba47404d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kruskal_results_lipid.head())\n",
    "print(pairwise_results_lipid.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88d77e-e74e-4ee2-abf8-27abe2495bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipid_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac247c97-0007-4f5a-aa3b-bc8fd3384629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlate_clinical_with_expression(df, clinical_vars=['Age', 'BMI', 'OGTT', 'HbA1c']):\n",
    "    expression = df.drop(columns=['#NAME', 'Diagnosis'] + clinical_vars)\n",
    "    clinical = df[clinical_vars]\n",
    "\n",
    "    corr_results = []\n",
    "\n",
    "    for clinical_var in clinical.columns:\n",
    "        for gene in expression.columns:\n",
    "            corr, pval = spearmanr(df[clinical_var], df[gene])\n",
    "            corr_results.append({\n",
    "                'Clinical_Variable': clinical_var,\n",
    "                'Feature': gene,\n",
    "                'SpearmanR': corr,\n",
    "                'p_value': pval\n",
    "            })\n",
    "\n",
    "    corr_df = pd.DataFrame(corr_results)\n",
    "    corr_df['adj_pval'] = multipletests(corr_df['p_value'], method='fdr_bh')[1]\n",
    "    sig_corrs = corr_df[corr_df['adj_pval'] < 0.05].sort_values('adj_pval')\n",
    "\n",
    "    # Top heatmap\n",
    "    top_corrs = sig_corrs.groupby('Clinical_Variable').head(5)\n",
    "\n",
    "    for var in clinical_vars:\n",
    "        top_feats = top_corrs[top_corrs['Clinical_Variable'] == var]['Feature']\n",
    "        if not top_feats.empty:\n",
    "            data = df[list(top_feats) + [var]]\n",
    "            corr_matrix = data.corr(method='spearman')\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(corr_matrix, annot=True, cmap='vlag', center=0)\n",
    "            plt.title(f'Spearman Correlation: {var} vs Top Features(gene expressions)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return sig_corrs\n",
    "significant_correlations_rnaseq = correlate_clinical_with_expression(rnaseq_merge)\n",
    "significant_correlations_rnaseq.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35d0e7-bcf1-449a-a0aa-f83e92fa0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_correlations_lipid = correlate_clinical_with_expression(lipid_merge)\n",
    "significant_correlations_lipid.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2696a73-5d64-4bbb-867a-e2485c7e1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Load lipid + clinical data (make sure lipid_merge.csv exists)\n",
    "lipid_df = pd.read_csv(\"lipid_merge.csv\")\n",
    "\n",
    "# Define clinical variables to correlate with\n",
    "clinical_vars = ['Age', 'BMI', 'OGTT', 'HbA1c']\n",
    "\n",
    "# Remove non-lipid columns\n",
    "lipid_features = lipid_df.drop(columns=['#NAME', 'Diagnosis'] + clinical_vars, errors='ignore')\n",
    "\n",
    "# Compute Spearman correlations for each clinical variable vs each lipid\n",
    "corr_results = []\n",
    "for clinical_var in clinical_vars:\n",
    "    for lipid in lipid_features.columns:\n",
    "        corr, pval = spearmanr(lipid_df[clinical_var], lipid_df[lipid])\n",
    "        corr_results.append({\n",
    "            'Clinical_Variable': clinical_var,\n",
    "            'Feature': lipid,\n",
    "            'SpearmanR': corr,\n",
    "            'p_value': pval\n",
    "        })\n",
    "\n",
    "# Create DataFrame and add absolute correlation column\n",
    "corr_df = pd.DataFrame(corr_results)\n",
    "corr_df['abs_corr'] = corr_df['SpearmanR'].abs()\n",
    "\n",
    "# Get top 5 features with highest absolute correlation per clinical variable\n",
    "top_corrs = corr_df.sort_values('abs_corr', ascending=False).groupby('Clinical_Variable').head(5)\n",
    "\n",
    "# Generate correlation heatmaps for each clinical variable\n",
    "for var in clinical_vars:\n",
    "    top_feats = top_corrs[top_corrs['Clinical_Variable'] == var]['Feature'].tolist()\n",
    "    if top_feats:\n",
    "        data = lipid_df[top_feats + [var]]\n",
    "        corr_matrix = data.corr(method='spearman')\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='vlag', center=0)\n",
    "        plt.title(f'Spearman Correlation: {var} vs Top Lipids')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a56a8-34b6-4503-b3c3-c4863bf07bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pandas as pd\n",
    "\n",
    "# Assume: rnaseq_merge has gene features + clinical variables\n",
    "clinical_vars = ['Age', 'BMI', 'OGTT', 'HbA1c']\n",
    "expression = rnaseq_merge.drop(columns=['#NAME', 'Diagnosis'] + clinical_vars, errors='ignore')\n",
    "\n",
    "results_rnaseq = []\n",
    "for var in clinical_vars:\n",
    "    for gene in expression.columns:\n",
    "        corr, pval = spearmanr(rnaseq_merge[var], rnaseq_merge[gene])\n",
    "        results_rnaseq.append({\n",
    "            'Clinical_Variable': var,\n",
    "            'Feature': gene,\n",
    "            'SpearmanR': corr,\n",
    "            'p_value': pval\n",
    "        })\n",
    "\n",
    "# Create DataFrame and adjust p-values\n",
    "df_rnaseq_corr = pd.DataFrame(results_rnaseq)\n",
    "df_rnaseq_corr['adj_pval'] = multipletests(df_rnaseq_corr['p_value'], method='fdr_bh')[1]\n",
    "\n",
    "# View top N\n",
    "df_rnaseq_corr.sort_values(by='adj_pval').head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1aa88e-74f6-477a-965e-f290870efa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rnaseq_corr.sort_values(by='adj_pval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af67208-5861-4465-ab63-3190c3f93ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume: lipid_merge has lipid features + clinical variables\n",
    "lipid_features = lipid_merge.drop(columns=['#NAME', 'Diagnosis'] + clinical_vars, errors='ignore')\n",
    "\n",
    "results_lipid = []\n",
    "for var in clinical_vars:\n",
    "    for lipid in lipid_features.columns:\n",
    "        corr, pval = spearmanr(lipid_merge[var], lipid_merge[lipid])\n",
    "        results_lipid.append({\n",
    "            'Clinical_Variable': var,\n",
    "            'Feature': lipid,\n",
    "            'SpearmanR': corr,\n",
    "            'p_value': pval\n",
    "        })\n",
    "\n",
    "# Create DataFrame and adjust p-values\n",
    "df_lipid_corr = pd.DataFrame(results_lipid)\n",
    "df_lipid_corr['adj_pval'] = multipletests(df_lipid_corr['p_value'], method='fdr_bh')[1]\n",
    "\n",
    "# View top N\n",
    "df_lipid_corr.sort_values(by='adj_pval').head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5866d-c8dd-4e17-86cc-cdba0349604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca_clustering_analysis(df, pca_components=2, n_clusters=3):\n",
    " \n",
    "    df.columns = df.columns.astype(str)\n",
    "\n",
    "    # Drop identifier column if exists\n",
    "    if '#NAME' in df.columns:\n",
    "        df = df.drop(columns=['#NAME'])\n",
    "\n",
    "    # Separate labels\n",
    "    if 'Diagnosis' not in df.columns:\n",
    "        raise ValueError(\"The dataset must contain a 'Diagnosis' column.\")\n",
    "\n",
    "    labels = df['Diagnosis']\n",
    "    X = df.drop(columns=['Diagnosis'])\n",
    "\n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "\n",
    "    # KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_ids = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    # Map numeric clusters to names\n",
    "    name_map = {i: f\"Cluster {chr(65+i)}\" for i in range(n_clusters)}\n",
    "    cluster_labels_named = pd.Series(cluster_ids).map(name_map)\n",
    "\n",
    "    # Plot PCA colored by Diagnosis\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=labels, palette='Set1')\n",
    "    plt.title(\"PCA - Colored by Diagnosis\")\n",
    "    plt.xlabel(f\"PC1 ({explained_var[0]*100:.1f}% var)\")\n",
    "    plt.ylabel(f\"PC2 ({explained_var[1]*100:.1f}% var)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title='Diagnosis', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot PCA colored by Clusters (named)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=cluster_labels_named, palette='Set2')\n",
    "    plt.title(f\"KMeans Clusters (k={n_clusters}) on PCA\")\n",
    "    plt.xlabel(f\"PC1 ({explained_var[0]*100:.1f}% var)\")\n",
    "    plt.ylabel(f\"PC2 ({explained_var[1]*100:.1f}% var)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: compute Adjusted Rand Index\n",
    "    label_encoded = pd.factorize(labels)[0]\n",
    "    ari = adjusted_rand_score(label_encoded, cluster_ids)\n",
    "\n",
    "    return {\n",
    "        \"explained_variance\": explained_var,\n",
    "        \"pca_components\": X_pca,\n",
    "        \"cluster_ids\": cluster_ids,\n",
    "        \"cluster_labels_named\": cluster_labels_named.tolist(),\n",
    "        \"adjusted_rand_index\": ari\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462665f-b9b5-4319-ad19-216fe4f6431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnaseq = run_pca_clustering_analysis(rnaseq_merge, pca_components=2, n_clusters=3)\n",
    "\n",
    "print(\"Explained variance by PC1 & PC2 for rnaseq:\", results_rnaseq['explained_variance'])\n",
    "print(\"Adjusted Rand Index (label vs clusters) for rnaseq:\", results_rnaseq['adjusted_rand_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9bcb8-3cc9-45d5-9f94-80dff520dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lipids = run_pca_clustering_analysis(lipid_merge, pca_components=2, n_clusters=3)\n",
    "\n",
    "print(\"Explained variance by PC1 & PC2 for lipid:\", results_lipids['explained_variance'])\n",
    "print(\"Adjusted Rand Index (label vs clusters) for lipid:\", results_lipids['adjusted_rand_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27044f77-063e-402d-862a-8aaed8b993e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
